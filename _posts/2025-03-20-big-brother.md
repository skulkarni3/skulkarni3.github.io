---
layout: post
title: Big Brother
subtitle: Ethical Dilemmas in Data Science
cover-img: /assets/img/path.jpg
thumbnail-img: /assets/img/thumb.png
share-img: /assets/img/path.jpg
tags: [ethics, blog]
author: Shruti Kulkarni
---

It’s hard to formulate a single definition that encompasses the different avenues of unethical practices that occur in the data science field. As such, my personal definition touches on five key areas: historically biased datasets, data malpractices, AI-generated code, Big Brother propaganda, and environmental impact of AI. 
To begin with, historically biased datasets when learned by machine learning models, perpetuate racial or gender biases that can further marginalize vulnerable communities. I’m not sure what would be an equitable solution but perhaps an “affirmative action” of sorts could be implemented in AI as a corrective measure. 
Similarly unethical practices in data science might have significant impact on peoples’ lives. Data scientists have the power to manipulate data and produce misleading insights either intentionally or unintentionally. I’d imagine an unintentional malpractice is simply the product of a lack of knowledge on how to appropriately handle an issue; while, intentional manipulation might be done to appease a boss or complete an urgent deadline. 
Alongside these issues, as AI is becoming increasingly common, future data scientists may resort to using AI-generated code out-of-convenience. Although doing so is extremely efficient, there’s a fine line between balancing original thought and plagiarism. Perhaps, as technology advances, writing code as a skill will eventually become obsolete as will these ethical considerations. 
The most troubling ethical dilemmas, in my opinion, are the final two points. Drawing from George Orwell’s “1989”, the concept of Big Brother represents a society under constant surveillance whose thoughts and behaviours are shaped by the government. Today, social media algorithms function in the same way - by intimately learning our internet habits and amplifying our confirmation biases. It’s terrifying how easily unregulated algorithms can easily spread misinformation and polarize populations.
Finally, the rise of large language models (LLMs) and AI across various platforms presents another critical concern: the environmental impact. Running these highly resource-intensive billion-parameter models requires enormous amounts of energy, leading to a significant carbon footprint. The environmental costs could have long-term, detrimental effects on our planet, exacerbating the global climate crisis.
